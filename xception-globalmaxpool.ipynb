{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy\nimport cv2\nimport os\nfrom tqdm import tqdm","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"../input/dynamic-sign-language-gestures-01/all\"\nimage_size = 256\nframe_rate = 0.1\n\ndef getFrame(sec):\n    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n    hasFrames,image = vidcap.read()\n    if hasFrames:\n#         image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        image = cv2.resize(image, (image_size, image_size))\n    return [hasFrames, image]","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"videos_list = sorted(os.listdir(path))[:500]\nnew_list = []\n\nfor xyz in tqdm(range(10)):\n    mno = xyz*50\n    for index in range(mno, mno+50):\n        new_list.append(videos_list[index])","execution_count":3,"outputs":[{"output_type":"stream","text":"100%|██████████| 10/10 [00:00<00:00, 49519.53it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"frames = []\nlabels = []\n\nfor video in tqdm(new_list):\n#     vidcap = cv2.VideoCapture(path + '/' + video)\n#     sec = 0\n#     mini = []\n#     success, frame = getFrame(sec)\n#     while success:\n#         mini.append(frame)\n#         sec = sec + frame_rate\n#         sec = round(sec, 2)\n#         success, frame = getFrame(sec)\n        \n#     frames.append(mini[-8:])\n    labels.extend([int(video[:3]) -1]*8)","execution_count":4,"outputs":[{"output_type":"stream","text":"100%|██████████| 500/500 [00:00<00:00, 435364.75it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\n# frames = numpy.array(frames)\nframes = numpy.load('../input/aslframes/last8-10classes.npy')\nlabels = numpy.array(labels)\ncat_labels = to_categorical(labels)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(frames, cat_labels, test_size=0.1,\n                                                   shuffle=True, random_state=42, stratify=labels)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.layers import GlobalMaxPooling2D, Dense, Dropout\nfrom tensorflow.keras.models import Model\n\nbase_model = Xception(include_top=False)\nembed = GlobalMaxPooling2D()(base_model.output)\nlayer = Dropout(0.4)(embed)\nlayer = Dense(1024, activation='relu')(layer)\nlayer = Dropout(0.4)(layer)\nlayer = Dense(256, activation='relu')(layer)\nlayer = Dense(64, activation='relu')(layer)\noutput = Dense(10, activation='softmax')(layer)\n\nmodel = Model(inputs=base_model.inputs, outputs=output)","execution_count":8,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n83689472/83683744 [==============================] - 1s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = False\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\ncheckpoint = tensorflow.keras.callbacks.ModelCheckpoint(filepath='model.h5', monitor='val_accuracy',\n                                                       save_best_only=True, verbose=1)\nearlyStop = tensorflow.keras.callbacks.EarlyStopping(patience=16, monitor='val_accuracy',\n                                                    restore_best_weights=True, verbose=1)\nreduceLR = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, \n                                                patience=4, verbose=1)\n\nmodel.fit(x_train, y_train, batch_size=32, epochs=128, verbose=1,\n          validation_data = (x_test, y_test),\n          callbacks=[checkpoint, earlyStop, reduceLR])","execution_count":9,"outputs":[{"output_type":"stream","text":"Epoch 1/128\n112/112 [==============================] - 20s 130ms/step - loss: 2.3681 - accuracy: 0.1972 - val_loss: 13.7203 - val_accuracy: 0.0950\n\nEpoch 00001: val_accuracy improved from -inf to 0.09500, saving model to model.h5\nEpoch 2/128\n112/112 [==============================] - 13s 116ms/step - loss: 1.7382 - accuracy: 0.3328 - val_loss: 28.6350 - val_accuracy: 0.1000\n\nEpoch 00002: val_accuracy improved from 0.09500 to 0.10000, saving model to model.h5\nEpoch 3/128\n112/112 [==============================] - 13s 116ms/step - loss: 1.5525 - accuracy: 0.4077 - val_loss: 23.1602 - val_accuracy: 0.1025\n\nEpoch 00003: val_accuracy improved from 0.10000 to 0.10250, saving model to model.h5\nEpoch 4/128\n112/112 [==============================] - 14s 124ms/step - loss: 1.4320 - accuracy: 0.4626 - val_loss: 16.9592 - val_accuracy: 0.1200\n\nEpoch 00004: val_accuracy improved from 0.10250 to 0.12000, saving model to model.h5\nEpoch 5/128\n112/112 [==============================] - 13s 115ms/step - loss: 1.3969 - accuracy: 0.4721 - val_loss: 30.1458 - val_accuracy: 0.1525\n\nEpoch 00005: val_accuracy improved from 0.12000 to 0.15250, saving model to model.h5\nEpoch 6/128\n112/112 [==============================] - 14s 121ms/step - loss: 1.3192 - accuracy: 0.5048 - val_loss: 20.3136 - val_accuracy: 0.1150\n\nEpoch 00006: val_accuracy did not improve from 0.15250\nEpoch 7/128\n112/112 [==============================] - 13s 116ms/step - loss: 1.3462 - accuracy: 0.4902 - val_loss: 26.4764 - val_accuracy: 0.1000\n\nEpoch 00007: val_accuracy did not improve from 0.15250\nEpoch 8/128\n112/112 [==============================] - 13s 119ms/step - loss: 1.2613 - accuracy: 0.5319 - val_loss: 24.0441 - val_accuracy: 0.0950\n\nEpoch 00008: val_accuracy did not improve from 0.15250\nEpoch 9/128\n112/112 [==============================] - 13s 117ms/step - loss: 1.2298 - accuracy: 0.5386 - val_loss: 32.1102 - val_accuracy: 0.1000\n\nEpoch 00009: val_accuracy did not improve from 0.15250\n\nEpoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\nEpoch 10/128\n112/112 [==============================] - 13s 116ms/step - loss: 1.1565 - accuracy: 0.5730 - val_loss: 31.2067 - val_accuracy: 0.1000\n\nEpoch 00010: val_accuracy did not improve from 0.15250\nEpoch 11/128\n112/112 [==============================] - 14s 121ms/step - loss: 1.0903 - accuracy: 0.6071 - val_loss: 33.4191 - val_accuracy: 0.1000\n\nEpoch 00011: val_accuracy did not improve from 0.15250\nEpoch 12/128\n112/112 [==============================] - 13s 116ms/step - loss: 1.1076 - accuracy: 0.5914 - val_loss: 30.2556 - val_accuracy: 0.0925\n\nEpoch 00012: val_accuracy did not improve from 0.15250\nEpoch 13/128\n112/112 [==============================] - 14s 123ms/step - loss: 1.0583 - accuracy: 0.5926 - val_loss: 33.5735 - val_accuracy: 0.1025\n\nEpoch 00013: val_accuracy did not improve from 0.15250\n\nEpoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\nEpoch 14/128\n112/112 [==============================] - 13s 116ms/step - loss: 1.0520 - accuracy: 0.6050 - val_loss: 33.3382 - val_accuracy: 0.1025\n\nEpoch 00014: val_accuracy did not improve from 0.15250\nEpoch 15/128\n112/112 [==============================] - 13s 116ms/step - loss: 1.0416 - accuracy: 0.6107 - val_loss: 33.1923 - val_accuracy: 0.1025\n\nEpoch 00015: val_accuracy did not improve from 0.15250\nEpoch 16/128\n112/112 [==============================] - 13s 120ms/step - loss: 1.0366 - accuracy: 0.6132 - val_loss: 33.3265 - val_accuracy: 0.1025\n\nEpoch 00016: val_accuracy did not improve from 0.15250\nEpoch 17/128\n112/112 [==============================] - 13s 115ms/step - loss: 1.0331 - accuracy: 0.6282 - val_loss: 33.2432 - val_accuracy: 0.1000\n\nEpoch 00017: val_accuracy did not improve from 0.15250\n\nEpoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\nEpoch 18/128\n112/112 [==============================] - 14s 123ms/step - loss: 1.0373 - accuracy: 0.6248 - val_loss: 33.2144 - val_accuracy: 0.1000\n\nEpoch 00018: val_accuracy did not improve from 0.15250\nEpoch 19/128\n112/112 [==============================] - 13s 115ms/step - loss: 1.0452 - accuracy: 0.6203 - val_loss: 33.1332 - val_accuracy: 0.1000\n\nEpoch 00019: val_accuracy did not improve from 0.15250\nEpoch 20/128\n112/112 [==============================] - 13s 115ms/step - loss: 1.0337 - accuracy: 0.6177 - val_loss: 33.1461 - val_accuracy: 0.1000\n\nEpoch 00020: val_accuracy did not improve from 0.15250\nEpoch 21/128\n112/112 [==============================] - 14s 122ms/step - loss: 1.0793 - accuracy: 0.5900 - val_loss: 33.0386 - val_accuracy: 0.1000\n\nEpoch 00021: val_accuracy did not improve from 0.15250\nRestoring model weights from the end of the best epoch.\n\nEpoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\nEpoch 00021: early stopping\n","name":"stdout"},{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7ff00c124350>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = True\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\ncheckpoint = tensorflow.keras.callbacks.ModelCheckpoint(filepath='model.h5', monitor='val_accuracy',\n                                                       save_best_only=True, verbose=1)\nearlyStop = tensorflow.keras.callbacks.EarlyStopping(patience=16, monitor='val_accuracy',\n                                                    restore_best_weights=True, verbose=1)\nreduceLR = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, \n                                                patience=4, verbose=1)\n\nmodel.fit(x_train, y_train, batch_size=32, epochs=128, verbose=1,\n          validation_data = (x_test, y_test),\n          callbacks=[checkpoint, earlyStop, reduceLR])","execution_count":10,"outputs":[{"output_type":"stream","text":"Epoch 1/128\n112/112 [==============================] - 24s 174ms/step - loss: 1.4438 - accuracy: 0.4415 - val_loss: 788.2791 - val_accuracy: 0.1000\n\nEpoch 00001: val_accuracy improved from -inf to 0.10000, saving model to model.h5\nEpoch 2/128\n112/112 [==============================] - 18s 164ms/step - loss: 0.7976 - accuracy: 0.7546 - val_loss: 389.5741 - val_accuracy: 0.1000\n\nEpoch 00002: val_accuracy did not improve from 0.10000\nEpoch 3/128\n112/112 [==============================] - 19s 168ms/step - loss: 0.4707 - accuracy: 0.8477 - val_loss: 652.3038 - val_accuracy: 0.1000\n\nEpoch 00003: val_accuracy did not improve from 0.10000\nEpoch 4/128\n112/112 [==============================] - 18s 162ms/step - loss: 0.4053 - accuracy: 0.8960 - val_loss: 667.8095 - val_accuracy: 0.1000\n\nEpoch 00004: val_accuracy did not improve from 0.10000\nEpoch 5/128\n112/112 [==============================] - 18s 163ms/step - loss: 0.2829 - accuracy: 0.9215 - val_loss: 1533.6976 - val_accuracy: 0.1000\n\nEpoch 00005: val_accuracy did not improve from 0.10000\n\nEpoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\nEpoch 6/128\n112/112 [==============================] - 19s 167ms/step - loss: 0.2438 - accuracy: 0.9282 - val_loss: 797.5897 - val_accuracy: 0.1000\n\nEpoch 00006: val_accuracy did not improve from 0.10000\nEpoch 7/128\n112/112 [==============================] - 18s 161ms/step - loss: 0.1283 - accuracy: 0.9625 - val_loss: 647.8741 - val_accuracy: 0.1000\n\nEpoch 00007: val_accuracy did not improve from 0.10000\nEpoch 8/128\n112/112 [==============================] - 18s 163ms/step - loss: 0.1075 - accuracy: 0.9665 - val_loss: 687.1158 - val_accuracy: 0.1000\n\nEpoch 00008: val_accuracy did not improve from 0.10000\nEpoch 9/128\n112/112 [==============================] - 18s 161ms/step - loss: 0.0786 - accuracy: 0.9745 - val_loss: 723.1074 - val_accuracy: 0.1000\n\nEpoch 00009: val_accuracy did not improve from 0.10000\n\nEpoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\nEpoch 10/128\n112/112 [==============================] - 19s 167ms/step - loss: 0.0699 - accuracy: 0.9766 - val_loss: 772.4528 - val_accuracy: 0.1000\n\nEpoch 00010: val_accuracy did not improve from 0.10000\nEpoch 11/128\n112/112 [==============================] - 18s 160ms/step - loss: 0.0717 - accuracy: 0.9778 - val_loss: 790.5865 - val_accuracy: 0.1000\n\nEpoch 00011: val_accuracy did not improve from 0.10000\nEpoch 12/128\n112/112 [==============================] - 19s 165ms/step - loss: 0.0583 - accuracy: 0.9823 - val_loss: 790.2316 - val_accuracy: 0.1000\n\nEpoch 00012: val_accuracy did not improve from 0.10000\nEpoch 13/128\n112/112 [==============================] - 19s 166ms/step - loss: 0.0646 - accuracy: 0.9784 - val_loss: 788.6368 - val_accuracy: 0.1000\n\nEpoch 00013: val_accuracy did not improve from 0.10000\n\nEpoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\nEpoch 14/128\n112/112 [==============================] - 18s 158ms/step - loss: 0.0643 - accuracy: 0.9760 - val_loss: 795.5783 - val_accuracy: 0.1000\n\nEpoch 00014: val_accuracy did not improve from 0.10000\nEpoch 15/128\n112/112 [==============================] - 19s 166ms/step - loss: 0.0522 - accuracy: 0.9808 - val_loss: 801.8172 - val_accuracy: 0.1000\n\nEpoch 00015: val_accuracy did not improve from 0.10000\nEpoch 16/128\n112/112 [==============================] - 18s 162ms/step - loss: 0.0702 - accuracy: 0.9746 - val_loss: 802.6198 - val_accuracy: 0.1000\n\nEpoch 00016: val_accuracy did not improve from 0.10000\nEpoch 17/128\n112/112 [==============================] - 19s 169ms/step - loss: 0.0641 - accuracy: 0.9815 - val_loss: 784.0621 - val_accuracy: 0.1000\n\nEpoch 00017: val_accuracy did not improve from 0.10000\nRestoring model weights from the end of the best epoch.\n\nEpoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\nEpoch 00017: early stopping\n","name":"stdout"},{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fef9c74e450>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(x_test)\n\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test.argmax(axis=1), y_pred.argmax(axis=1))","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"0.1"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0, 40],\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 40],\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 40],\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 40],\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 40],\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 40],\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 40],\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 40],\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 40],\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 40]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}